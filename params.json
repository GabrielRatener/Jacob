{"name":"Jacob","tagline":"A lexer and parser generator in JavaScript for DSL and custom languages in the browser and Node.js","body":"# JACOB\r\n Possibly Acronym for: JAvascript COmpiler Bison-like\r\n Or maybe even Just Another Compiler to OBjects\r\n\r\nJacob is a tool like Flex and Bison to generate interpreters or compilers. This can be used for example to create a DSL (domain specific language) to be used in NodeJS or in the browser.\r\n \r\nGenerating a language interpreter (or compiler) involves two steps: \r\n 1. aggregate the input characters into a series of \"tokens\": this is done by a module called \"lexer\"\r\n 2. interpreting the series of tokens as a language, according to a grammar, this is done by a module called \"parser\".\r\n \r\nAlso, you will define an actual behaviour which is the semantic of the language, that is, what the program should do according to a language statement.\r\n \r\nGiven appropiate instructions, Jacob will generate both the lexer and the parser. We'll see how to specify the actual behaviour of your parser.\r\n\r\nUsage\r\n=====\r\nFrom a command line to generate the lexer use the following command line:\r\n\r\n`jacob -t tokens.jacoblex [-l lexer.js]`\r\n\r\nThe `-t` argument specify the token specifications file, the optional `-l` parameter specify the name of the generated file. For the token specification file extension you can use whatever extension you want (here I used .jacoblex) except .js since .js file will be interpreted as javascript modules containing the internal representation of the tokens. You could also use this instead of the lexer language descripted later, this will be documented in the future.\r\n\r\nAnalogously to generate the parser you would use:\r\n\r\n`jacob -g grammar.jacobgram [-p parser.js]`\r\n\r\nUsually you'll generate both modules with just one invocation:\r\n\r\n`jacob -t tokens.jacoblex [-l lexer.js] -g grammar.jacobgram [-p parser.js]`\r\n\r\n\r\n\r\n\r\nLexer\r\n=====\r\n\r\nIn order for Jacob to create a lexer you have to provide it with a .jacoblex file which looks something like the following:\r\n\r\n```[JavaSCript]\r\n\r\n%moduleName MyLexer\r\n\r\n%%\r\n\r\ndigits = [0-9]\r\n\r\n%%\r\n<>{digits}*\\.{digits}+    {\r\n    this.jjval = parseFloat(this.jjtext);\r\n    return 'float';\r\n}\r\n\r\n<>{digits}+   {\r\n    this.jjval = parseInt(this.jjtext);\r\n    return 'integer';\r\n}\r\n\r\n<>print {\r\n  return 'print';\r\n}\r\n\r\n<>\\w+ { return 'id'; }\r\n\r\n<>\\s* { }\r\n\r\n<>.   { return this.jjtext; }\r\n\r\n<>$   { console.log('EOF'); return 'EOF'; }\r\n```\r\n\r\nThe syntax is similar to Flex's, with some differences.\r\nThe file is split in three areas, separated by a double percent. In the first area are the directives. The only currently supported is %moduleName, which allow you to specify the name of the generated module.\r\n\r\nThe second section contains definitions, that allows you to assign names to regular expressions.\r\n\r\nThe third section contains the actual ules. In order to recognize a token, you specify the regular expression that matches it, and then assign it an action.\r\n\r\nTake for example the following:\r\n```[JavaSCript]\r\n<>\\w+ { return 'id'; }\r\n```\r\n\r\nThe double angled brakets are used to specify (optional) starting state of the rule (more on that later), in this case the rule is active in the DEFAULT state. \r\nThe regular expression `\\w+` matches one or more alphanumeric chars. \r\nThe associated action (between curly braces) is a javascript function that should return the name of the matched token.\r\nThis name is the name that can then be used in the grammar file.\r\n\r\nRegular Expressions Syntax\r\n=======================\r\n\r\nJacob implements most, if not all, the regular expressions mechanism found in most lexer, including forward lookahead.\r\nHere is a summary:\r\n\r\n| pattern | description |\r\n|---------|-------------|\r\n| x       | matches character 'x' |\r\n| . | matches any character except newline |\r\n| [xyz] | this is a character class: it matches either 'x','y' or 'z' |\r\n| [a-f] | character class with range: it matches every character from 'a' to 'f' included |\r\n| [^a-f] | range negation: matches everything BUT 'a'-'f' |\r\n| r* | matches 0 or more times the regular expression r |\r\n| r+ | matches 1 or more times r |\r\n| r? | matches 0 or 1 r |\r\n| r{2,5} | matches from 2 to 5 r |\r\n| r{2,} | matches 2 or more r |\r\n| r{,5} | matches from 0 to 5 r |\r\n| r{4} | matches r exactly 4 times |\r\n| {digits} | matches the definition named 'digits' |\r\n| \\X | '\\' is the escape character, can be used to insert character like '\\n','\\r','\\t' or to escape regex special character like \\* |\r\n| \\x2a | matches character with hex code 2a |\r\n| \\u2103 | matches unicode character U+2103 |\r\n| rs | the regular expression r followed by the regular expresson s |\r\n| r&#124;s | either r or s |\r\n| r/s | lookahead: matches r only if it is followed by s |\r\n| ^r | matches r only at the beginning of a line |\r\n| r$ | matches r only at the end of a line |\r\n| ab(cd)* | matches ab, abdc, abcdcd, abcdcdcd ecc. |\r\n\r\n\r\n\r\n\r\nLexer Actions\r\n============\r\nIn the actions you should specify what the lexer should do after recognizing a token. The simplest action is the empty one;\r\n\r\n`<>\\s* { }`\r\n\r\nThis is useful to ignore a given input. Since the action won't return any token name, the lexer will continue processing the input without outputting any token for the matched content, thus in fact ignoring that input. In the example above the whitespace is ignored.\r\n\r\nAnother common situation is having to parse the input to have a meaningful token:\r\n```[JAvaScript]\r\n<>{digits}+   {\r\n    this.jjval = parseInt(this.jjtext);\r\n    return 'integer';\r\n}\r\n```\r\nInside actions, this points to the lexer itself. In the lexer `jjtext` contains the text that the regular expression matched. `jjval` by default contains the same text as`jjtext` but you can change it inside an action. In the example above the text is parsed to get an integer value, which is then stored in `jjval`.\r\nNote that `jjval` is the value that is used in the parsing phase by your interpreter/compiler.\r\nAnother powerful thing you could do inside an action is to change the lexer's state. Take this example:\r\n\r\n```[JavaScript]\r\n<>\\/\\*    {this.pushState('BLOCKCOMMENT');}\r\n<BLOCKCOMMENT>\\*\\/    {this.popState();}\r\n<BLOCKCOMMENT>(\\n|\\r|.) {}\r\n```\r\n\r\nWhen the lexer encounters a `/*` sequence, it will enter a BLOCKCOMMENT state because of the action `this.pushState('BLOCKCOMMENT');`. In this state, the only active rules art the ones in which the state list (the list inside angular brackets) contains the BLOCKCOMMENT identifier. So while the lexer is in BLOCKCOMMENT state, it whill ignore any character because of the rule `(\\n|\\r|.) {}`\r\nThe only way to change the state is to encounter a `*/` sequence in which the action `this.popState();` while resume the state that was active before encountering the first `/*` sequence.\r\nThe previous rules thus can be used to ignore block comments with a C-like syntax.\r\n\r\nHere is a table of all the members of the generated lexer that are available for you inside the actions:\r\n\r\n| member | description |\r\n|--------|-------------|\r\n| jjtext | the text matched by the regex |\r\n| jjval | the value of the current token, by default the same as jjtext |\r\n| jjpos | the position of the current token inside the input string |\r\n| less(n)| this function can be called to push back n character into the input stream |\r\n| isEOF()| returns true if the input is at the end |\r\n\r\nOf courser the generated Lexer is a JavaScript object, so you can dynamically add any member or method you need in your actions.\r\n\r\n\r\nParser\r\n======\r\n\r\nIn order to generate a parser you need to give Jacob the specification file containing an attributed grammar which describes the language you want to interpret/compile. Simply put, the grammar file will contains the grammar rules and the actions that the parser must execute after recognizing each rule.\r\nJacob can generate **SLR**, **LALR** and **LR1** parser type. If not specified, Jacob will choose the most appropiate parser type given the grammar.\r\n\r\nHere is an example of a jacob grammar file:\r\n\r\n\r\n```[Javascript]\r\n%moduleName MyParser\r\n\r\n%left 'PLUS' '-'\r\n%left '*' '/'\r\n\r\nProgram = { Statement } function(){};\r\n\r\nStatement = 'id' '=' Expression function(id,_, exp){this[id] = exp;}\r\n            | 'print' Expression function(_,exp){ console.log(exp);} ;\r\n\r\nExpression = Expression 'PLUS' Expression  function (e1, _, e2) {\r\n                                                             return e1 + e2;\r\n                                                         }\r\n            | Expression '-' Expression function (e1, _, e2) {\r\n                                                              return e1 - e2;\r\n                                                          }\r\n            | Expression '*' Expression function (e1, _, e2) {\r\n                                                             return e1 * e2;\r\n                                                         }\r\n             | Expression '/' Expression function (e1, _, e2) {\r\n                                                               return e1 / e2;\r\n                                                           }\r\n             | 'integer'  function (i) {\r\n                                             return i;\r\n                                         }\r\n             | 'id'  function (id) {\r\n                                        return this[id];\r\n                                    }\r\n             | '(' Expression ')'   function (_, e) {\r\n                                                         return e;\r\n                                                     }\r\n\r\n;\r\n\r\n```\r\n\r\nDirectives\r\n----------\r\nAt the top of the file you define directives, those can be:\r\n\r\n`%moduleName <name>` sets the name of the generated module\r\n\r\n`%mode SLR|LALR|LR1` sets the type of the generated parser. If not provided the simplest type able to parse the grammar is used.\r\n\r\n`%left|%right token1 [token2 token3...]` sets the precedence and the associativity of an operator. The operator defined first have lower precedence. The name used for the tokens should be the ones that the lexer is returning in their actions. They could be the actual input character (es: '-', '°') or an actual name (es: 'PLUS') the important thing is that they match what the lexer is returning.\r\n\r\n`%nonassoc` tells the parser that that token is not associative, so that it will raise an error whenever it will be used is an expression with other operator of the same precedence.\r\n\r\nEBNF\r\n----\r\nTha actual grammar is specified in Extended Backus–Naur Form, with every rule followed by an action consisting in a javascript function.\r\n\r\nThe EBNF in the example defines rules using Nonterminal symbols (Program, Statement, Expression, ...) and terminal symbols ('(', ')', 'integer', '*',...). Terminal symbols are contained in single quotes and should match the name of the tokens as yielded by the lexer.\r\n\r\nEach production can have several alternatives (separated by the pipe symbol) and each alternative can have its own action function. The action function will receive a parameter for each element of the corresponding right-hand-side part of the production.\r\n\r\nEach rule is then terminated with a semicolon (;).\r\n\r\nEBNF is more handier than BNF because it also adds shortcuts to define repetitions, optionals and grouping:\r\n\r\n`{ ... }` means 0 or more (...)\r\n`[ ... ]` means 0 or one (...)\r\n`( ... )` will group the content into one group. This is useful to inline some rules that don't need a special action for themselves, for example:\r\n\r\n`Assignment = Identifier  ':='  ( 'integer' | Identifier | 'string' )  function(id,_,rhsvalue) { ... };`\r\n\r\n\r\n\r\n\r\n ","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}